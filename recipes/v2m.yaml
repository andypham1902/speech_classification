# Model arguments
model_name_or_path: tf_efficientnetv2_m.in21k_ft_in1k

do_train: true
do_eval: false
overwrite_output_dir: true
gradient_checkpointing: false
gradient_checkpointing_kwargs:
  use_reentrant: false

# Training arguments
ddp_find_unused_parameters: true
train_data_file: data/train_question.csv
fold: 0
fp16: true
learning_rate: 0.001
per_device_train_batch_size: 32
per_device_eval_batch_size: 32
gradient_accumulation_steps: 1
# eval_accumulation_steps: 1
optim: adamw_bnb_8bit
load_best_model_at_end: true
num_train_epochs: 50
eval_strategy: epoch
save_strategy: epoch
# eval_strategy: steps
# save_strategy: steps
# eval_steps: 1
# save_steps: 1
save_total_limit: 10
metric_for_best_model: f1
greater_is_better: true
output_dir: v2s-test
dataloader_num_workers: 8
logging_steps: 10
warmup_ratio: 0.05
ignore_data_skip: true
report_to: none
